\newchap{Related Work}
\label{chap:2_related_work}
This chapter explores the dynamic field of Optical Character Recognition (OCR), tracing the evolution of this pivotal technology and the development of sophisticated post-OCR correction techniques that enhance the utility of OCR outputs. A detailed exploration of TrOCR, a state-of-the-art (SOTA) OCR model, alongside CharBERT, a large language model, forms a significant portion of this chapter, with an emphasis on their architectures and training methodologies. These two models are central to this study due to their innovative integration potential. Additionally, the concept of candidate fusion is discussed, which leverages the strengths of both OCR and language models to improve text recognition accuracy. The chapter also examines the advantages of incorporating glyph analysis into model training, further refining the recognition process. Overall, this chapter reviews the current advancements in OCR technology and sets the stage for the introduction of a novel composite model designed to synergistically combine these technologies, tackling the challenges associated with precise text recognition and correction.

\section{Optical Character Recognition (OCR)}
\label{sec:2_ocr}
According to \cite{philips2020historical}, the digitization of historical documents involves several critical phases, each leveraging advanced technologies and methodologies to transform ancient texts into accessible digital formats. The process begins with image acquisition, where physical documents are converted into digital images through scanning or photography. Following this, preprocessing steps such as binarization, using methods like Otsu’s algorithm \citep{liu2009otsu} to simplify images into binary formats, and layout analysis to determine structural elements like text blocks, are essential for preparing images for text recognition. Text recognition is then performed using technologies like OCR and Handwritten Text Recognition (HTR), with modern approaches often employing Convolutional Neural Networks (CNNs) \citep{zhang2017cnn} and Long Short-Term Memory networks (LSTMs) \citep{breuel2013high} to enhance accuracy. This comprehensive process is depicted in \autoref{fig:2_ocr_process}.

\fig{images/ocr_process.png}{fig:2_ocr_process}{Digitization Process of Historical Documents}{15}{Digitization Process of Historical Documents}

The paper by \cite{karthick2019steps} elaborates on the OCR process, detailing the critical stages involved and exploring recent advancements in the field: 1) preprocessing; 2) feature extraction; 3) recognition. Initially, during preprocessing, the image quality is enhanced by removing noise, adjusting contrast, and segmenting the image to prepare it for analysis. This stage sets the foundation for feature extraction, where unique characteristics of the text are identified, which are crucial for accurate recognition. Following this, the recognition stage classifies these features into textual data. This text is then refined during the post-processing stage, where errors are corrected, and text clarity is improved. Before feature extraction, additional steps such as further segmentation and morphological processing are applied to enhance the text structure in the images. The process is illustrated in \autoref{fig:2_ocr}.

\fig{images/ocr.png}{fig:2_ocr}{Stages of the Optical Character Recognition (OCR) Process}{11}{Stages of the Optical Character Recognition (OCR) Process}

While traditional models typically handle the processes of preprocessing, feature extraction, and recognition in separate, discrete stages, there are modern OCR models that operate on an end-to-end basis \citep{huang2021multiplexed}\citep{neudecker2019ocr}\citep{belay2020amharic}. These end-to-end models streamline the text recognition process by integrating all these stages into a single continuous workflow. This approach leverages advanced machine learning techniques, particularly deep learning, to directly process raw images of text into editable text outputs. This not only simplifies the OCR process by eliminating the need for manual feature engineering and separate processing stages but also enhances the system’s ability to handle varied and complex text presentations.

\section{Post-OCR correction}
\label{sec:2_post-ocr_correction}
After text recognition, post-processing corrects OCR errors through techniques such as spell checking and contextual adjustments based on language models. The final phase involves applying Natural Language Processing (NLP) for tasks like information retrieval, enabling further analysis and interpretation of the content. Tools like Tesseract \citep{smith2007overview} and Transkribus \citep{kahle2017transkribus} are pivotal in these processes, supporting both OCR and HTR tasks, while datasets such as the IAM Historical Document Database \citep{marti1999full} provide crucial benchmarks for training and evaluating technology performance. These stages collectively address the various challenges presented by the poor quality of many historical documents, the diversity of handwriting styles, and the computational demands of processing such data, underscoring the ongoing need for innovation in this field.

\cite{mokhtar2018ocr} points out that the structured and predictable nature of OCR errors makes them suitable for correction using machine learning models. They proposed two deep learning models: a word-based sequence-to-sequence model and a character-based model, allowing them to correct individual characters and handle words not seen during training. The findings show that while the word-based model struggles with unseen words, the character-based model, particularly when combined with normalization, performs well across different datasets, suggesting its practical applicability in improving OCR accuracy in real-world settings.

\section{TrOCR}
\label{sec:2_trocr}
OCR tasks typically involve text detection and text recognition. TrOCR is a Transformer-based model which focuses on the text recognition part of the OCR task, converting images to texts. Therefore, the input should be sliced into line images, each with a single line of transcription on it. Unlike previous advancements in text recognition, TrOCR uses a pre-trained vision Transformer (ViT) \citep{dosovitskiy2020image} for image feature extraction and a text Transformer \citep{vaswani2017attention} for sequence-to-sequence learning instead of CNN backbones \citep{wang2020cspnet} and Connectionist Temporal Classification (CTC) \citep{graves2006connectionist}. It eliminates the usage of external large language models (LLMs) and can be extended for multilingual purposes by leveraging pre-trained language models (LMs) of different languages. In addition, unlike traditional OCR systems that rely on feature engineering and pre-/post-processing, TrOCR allows contextual learning, leading to SOTA results in challenging scenarios.

The encoder of TrOCR is initialized by pre-trained ViT-style models such as Data-Efficient Image Transformer (DeiT) \citep{touvron2021training} or Bidirectional Encoder representation from Image Transformers (BEiT) \citep{bao2021beit}, while the decoder initialization uses pre-trained Bidirectional Encoder Representations from Transformers (BERT)-style models such as RoBERTa \citep{liu2019roberta}\TODO{Need full name?} or MiniLM \citep{wang2020minilm}. Both of them are Transformer encoder structures. Therefore, the missing encoder-decoder attention in the TrOCR decoder is initialized randomly for training. Due to the fixed input length of Transformers, the image is first resized to 384$\times$384, and then split into 16$\times$16 patches before inputting into the Transformer. Unlike CNNs, Transformers do not have spatial information of the input data. Thus, positional encodings are added to the patches to preserve the spatial structures of the input images.

TrOCR is pre-trained on synthetic data and SROIE \citep{huang2019icdar2019}, IAM datasets sequentially. TrOCR\textsubscript{LARGE} (total parameters=558M), initialized by BEiT\textsubscript{LARGE} and RoBERTa\textsubscript{LARGE}, reached a character error rate (CER) \citep{klakow2002testing}\citep{wang2003word} of 2.89 by pre-training on the synthetic data and the IAM dataset.

So far, TrOCR is considered a SOTA model for OCR on both printed and handwritten tasks. Although its design and capabilities represent a significant advancement in the field of OCR, deficiencies still exist. In scenarios where the text layout is curved or vertical, TrOCR's performance is compromised. Note that these limitations are not unique to TrOCR but are rather common challenges for most OCR models. In this study, TrOCR will serve as the baseline. This foundational benchmark will be improved through integration with LMs to refine and correct the output results.

\section{CharBERT}
\label{sec:2_charbert}
CharBERT \citep{ma2020charbert} is an enhancement of BERT \citep{devlin2018bert}, which aims to address problems in Byte-Pair Encoding (BPE) \citep{sennrich2015neural} used by pre-trained language models like BERT and RoBERTa. It has the same model structure and configuration as BERT and RoBERTa, depending on the initialization. During inference, it takes text as input and outputs a representative embedding of the text.

Pre-trained language models like BERT and RoBERTa have achieved outstanding results in NLP tasks. Both models use BPE to encode input data. BPE is capable of encoding almost all vocabularies, including out-of-vocabulary (OOV) words. It breaks down OOV words into subwords until they are in its vocabulary dictionary. In addition, it allows efficiency in vocabulary space. For instance, BPE can represent different forms of a word (e.g., \say{run}, \say{running}, \say{runs}) with their common subwords, which results in a smaller set of total tokens. However, BPE has the problems of incomplete modeling and fragile representation.

Incomplete modeling refers to the inability of BPE to fully encapsulate the complete aspects of a word. BPE splits words into subword units. While these small pieces are helpful for understanding parts of the word, they may not entirely convey the meaning or nuances of the whole word. For instance, the word \say{understand}, which will be broken down into \say{under} and \say{stand} by BPE, means comprehending a concept. However, its meaning is not merely a combination of \say{under} and \say{stand}.

Fragile representation highlights BPE's sensitivity to minor typos in a word. In other words, a small spelling mistake can result in drastic changes in the set of subwords. For instance, BPE processes \say{cat} as a known subword. However, if an error occurs, resulting in \say{cta}, BPE will break down the word into individual characters: \say{c}, \say{t}, and \say{a}. In this example, a minor rearrangement of letters in \say{cat} causes significant changes in how BPE interprets the word.

CharBERT aims to address these two problems with two tricks in the pre-training stage: 1) employ a dual-channel architectural approach for the subword and character; 2) utilize noisy language modeling (NLM) and masked language modeling (MLM) for unsupervised character representation learning. The first trick processes both subword and character-level information and fuses them, ensuring a more robust representation in case of typos. The second trick involves introducing character-level noise into words and training the model to correct these errors. This approach enhances the model's ability to handle real-world text with variations and typos. Besides, it also masks 10\% of words and trains the model to predict them. This enables CharBERT to synthesize information on a token level.

CharBERT is fine-tuned on several downstream tasks, including question answering, text classification, and sequence labeling. CharBERT outperforms BERT across all tasks. However, it encounters some challenging competition from RoBERTa, which the authors acknowledge as a robust baseline as shown in \autoref{fig:2_charbert_result}.

\fig{images/charbert_result.png}{fig:2_charbert_result}{Experimental Results of CharBERT and Strong Pre-trained Models\\Image source: \url{https://aclanthology.org/2020.coling-main.4/}}{15}{Experimental Results of CharBERT and Strong Pre-trained Models}

Although the performance of CharBERT does not significantly exceed that of RoBERTa, the model architecture of CharBERT is intriguing. Since models are usually better at the tasks they are pre-trained on, the NLM pre-training task makes CharBERT a potentially good corrector, which can be paired with the recognizer and compensate for its language deficiencies. In addition, we can further pre-train the NLM with common OCR mistakes instead of randomly introduced errors. This makes the corrector more familiar with OCR-specific errors.

\section{Candidate Fusion}
\label{sec:2_candidate_fusion}
Candidate fusion \citep{kang2021candidate} is a technique that involves integrating the LM within the recognizer, i.e., letting the LM and the recognizer interact. Most SOTA word recognition models and LMs are trained separately. However, with candidate fusion, several advantages can be achieved. First, the recognizer is able to integrate insights from both its own processing and the input from the LM, resulting in a more comprehensive understanding. Second, the system is designed to assess the information supplied by the LM, allowing the recognizer to selectively weigh its importance. Lastly, the LM can learn from frequent errors generated by the recognizer, improving overall accuracy.

The models utilized for demonstrating candidate fusion have an encoder-decoder structure, where the encoder extracts features from input images, and the decoder converts the image features into text. The encoder is a CNN followed by a Gated Recurrent Unit (GRU) \citep{dey2017gate}, and the decoder is an unidirectional multi-layered GRU. Both structures in the encoder provide spatial information about the input, allowing the decoder to follow the proper order.

In the paper, they employ two-step training. In the first step, the LM is pre-trained on a large corpus for it to understand general language and grammar. In the second step, the LM is further trained alongside handwritten datasets with the recognizer. This allows the LM to consider both its own knowledge and what the recognizer predicts when outputting the result text. The LM will adjust its predictions by taking into account the recognizer's decisions.

The model is being evaluated on IAM, GW \citep{fischer2012lexicon}, and Rimes \citep{grosicki2011icdar}. Among the datasets, the model shows significant improvement on GW over a strong baseline \citep{8395102}. However, the performance of this model beyond the GW dataset remains questionable, as the improvements are relatively small. Additionally, these other datasets encompass more writers, contributing to a greater diversity in handwriting styles. Consequently, the model's marked improvement on the GW dataset might indicate potential limitations in its adaptability to diverse handwriting styles.

Despite the potential deficiency in the model, the idea of fusing the recognizer and the LM and allowing both of them to learn from each other is a quality design worth exploring. This technique provides new opportunities for achieving more context-aware text recognition. In this study, TrOCR and CharBERT will serve as the recognizer and the LM, respectively, and will be combined. The composite model aims to explore the potential enhancements or effects they can bring when used together.

\section{Glyph Embedding}
\label{sec:2_glyph_embedding}
Integrating the concept of glyphs into OCR offers substantial advantages, especially for the digitization of historical texts. This approach enhances the accuracy of character recognition by focusing on glyphs—the visual forms of characters—which is crucial for handling the varied typographic styles found in historical documents. Glyph-based OCR is adept at adapting to these styles and is particularly effective at recognizing characters in texts that are in poor condition, such as those with faded ink or smudges. By understanding the visual aspects of glyphs, such systems significantly reduce OCR errors, minimizing the need for labor-intensive post-correction. Additionally, since this method is based on visual characteristics rather than language, it can be applied across different languages and scripts, making it highly versatile.

\cite{amrhein2018supervised} explore how Neural Machine Translation, when applied at the character level, can be particularly effective for correcting glyph-based errors. This approach leverages the flexibility of neural machine translation (NMT) to adapt to the nuances of character shapes and their common misinterpretations, thereby improving the accuracy of OCR text post-correction. Overall, the integration of glyph analysis into OCR workflows as discussed in this paper not only improves the initial accuracy of text digitization but also enhances the efficiency of processing large volumes of historical documents.