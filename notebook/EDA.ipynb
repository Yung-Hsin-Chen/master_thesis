{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install --upgrade pip\n",
    "%pip install torchvision\n",
    "%pip install scikit-learn\n",
    "%pip install PyYAML\n",
    "%pip install Pillow\n",
    "%pip install torch\n",
    "%pip install matplotlib\n",
    "%pip install tensorflow\n",
    "%pip install langdetect\n",
    "%pip install wikipedia\n",
    "%pip install tqdm\n",
    "%pip install transformers\n",
    "%pip install boto3\n",
    "%pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "required_version = (3, 9)\n",
    "\n",
    "if sys.version_info < required_version or sys.version_info >= (3, 10):\n",
    "    sys_version = str(sys.version).split(\" \")[0]\n",
    "    raise Exception(f\"This notebook requires Python 3.8, but the current version is {sys_version}.\")\n",
    "else:\n",
    "    from src.utils.notebooks import *\n",
    "    from src.processor.data_loader import get_data_loader, get_split_indices\n",
    "    from src.utils.helpers import load_data\n",
    "    import config.model_config as cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GW, IAM Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader_keys = cfg.trocr_charbert[\"experiment1\"][\"data_loader_keys\"]\n",
    "gw_data_loaders, iam_data_loaders, bullinger_data_loaders, icfhr_data_loaders = get_data_loader(**data_loader_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dataset Information\n",
    "- **text lines:** The total number of text lines in the dataset.\n",
    "- **unique word instances:** The count of distinct words present in the dataset.\n",
    "- **unique letters:** The number of different letters (characters) used across all text lines (include punctuations).\n",
    "- **average text line length:** The average number of characters (letters and spaces) per text line.\n",
    "- **average word length:** The average number of characters per word in the dataset.\n",
    "- **None in ground truth:** he count of occurrences where the ground truth is the value \"None.\"\n",
    "- **percentage of non-character:** The percentage of characters in the dataset that are not part of the standard alphabet. This may include punctuation marks and other non-alphabetic characters. (characters other than A-Za-z0-9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GW Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gw_image, gw_gt = get_dataset(GW_GT_PATH, GW_IMAGE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_text_lines(gw_image, gw_gt, \"gw\", gw_data_loaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_dataset_info(GW_GT_PATH, GW_IMAGE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise_dataset(GW_GT_PATH, GW_IMAGE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_punctuations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IAM Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iam_image, iam_gt = get_dataset(IAM_GT_PATH, IAM_IMAGE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_text_lines(iam_image, iam_gt, \"iam\", iam_data_loaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_dataset_info(IAM_GT_PATH, IAM_IMAGE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise_dataset(IAM_GT_PATH, IAM_IMAGE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bullinger Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bullinger_image, bullinger_gt = get_dataset(BULLINGER_GT_PATH, BULLINGER_IMAGE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_text_lines(bullinger_image, bullinger_gt, \"bullinger\", bullinger_data_loaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_dataset_info(BULLINGER_GT_PATH, BULLINGER_IMAGE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise_dataset(BULLINGER_GT_PATH, BULLINGER_IMAGE_PATH, \"Bullinger\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ICFHR 2016 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icfhr_image, icfhr_gt = get_dataset(ICFHR_GT_PATH, ICFHR_IMAGE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_dataset_info(ICFHR_GT_PATH, ICFHR_IMAGE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Images with gt==None: \")\n",
    "for image, gt in zip(icfhr_image.items(), icfhr_gt.items()):\n",
    "    if gt[1]==None:\n",
    "        print(image[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise_dataset(ICFHR_GT_PATH, ICFHR_IMAGE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wikipedia Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config.config_paths import DATA_PROCESSED, DATA_RAW\n",
    "WIKI_TRAIN_PATH = os.path.join(\".\", \"data\", \"wiki\", \"enwiki_train.txt\")\n",
    "WIKI_VAL_PATH = os.path.join(\".\", \"data\", \"wiki\", \"enwiki_val.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_wiki_lines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wiki_dataset_info(path):\n",
    "    with open(path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        line_count = len(lines)\n",
    "        formatted_line_count = \"{:,}\".format(line_count).replace(\",\", \"'\")\n",
    "    print(lines[:5])\n",
    "    # info = {\"text lines\": formatted_line_count,\n",
    "    #         \"unique word instances\": len(all_words),\n",
    "    #         \"unique letters\": len(set(all_gt)),\n",
    "    #         \"average text line length\": get_average_len(list(gt_dict.values())),\n",
    "    #         \"average word length\": get_average_len(list(all_words)),\n",
    "    #         \"None in ground truth\": list(gt_dict.values()).count(None),\n",
    "    #         \"percentage of non-character\": calculate_non_alphanumeric_percentage(all_gt)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_dataset_info(WIKI_VAL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_info(gt_path, image_path):\n",
    "    image_dict, gt_dict = get_dataset(gt_path, image_path)\n",
    "    all_gt = \" \".join([i for i in gt_dict.values() if i])\n",
    "    all_words = set(all_gt.split(\" \"))\n",
    "    word_frequencies = get_word_frequencies(all_gt)\n",
    "    word_frequencies = sorted(word_frequencies.items(), key=lambda x: x[1], reverse=True)\n",
    "    # average_length = get_average_text_line_len(list(gt_dict.values()))\n",
    "    info = {\"text lines\": len(gt_dict),\n",
    "            \"unique word instances\": len(all_words),\n",
    "            \"unique letters\": len(set(all_gt)),\n",
    "            \"average text line length\": get_average_len(list(gt_dict.values())),\n",
    "            \"average word length\": get_average_len(list(all_words)),\n",
    "            \"None in ground truth\": list(gt_dict.values()).count(None),\n",
    "            \"percentage of non-character\": calculate_non_alphanumeric_percentage(all_gt)}\n",
    "    print(\"Metric                       | Value\")\n",
    "    print(\"----------------------------------------\")\n",
    "    for k,v in info.items():\n",
    "        if type(v)==float:\n",
    "            print(f\"{k:<28} | {v:.2f}\")\n",
    "        else:\n",
    "            print(f\"{k:<28} | {v}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "    plot_freq(word_frequencies[:10], word_frequencies[-10:], \"Top 10 Least Frequent Words\")\n",
    "    return"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
